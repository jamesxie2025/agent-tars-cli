# Agent TARS CLI Configuration
# For use with @agent-tars/cli

# ============================================
# Model Provider API Keys
# ============================================
# Agent TARS will auto-detect which provider to use based on available keys

# ModelScope (Qwen)
MODELSCOPE_API_KEY=your-modelscope-api-key

# DeepSeek
DEEPSEEK_API_KEY=your-deepseek-api-key

# OpenAI (GPT-4o, etc.)
OPENAI_API_KEY=

# Anthropic (Claude)
ANTHROPIC_API_KEY=

# VolcEngine (Doubao/豆包)
VOLCENGINE_API_KEY=

# ============================================
# Optional MCP Tools API Keys
# ============================================

# Brave Search (for web search)
BRAVE_API_KEY=

# GitHub (for repository operations)
GITHUB_TOKEN=

# PostgreSQL (connection string)
POSTGRES_CONNECTION_STRING=

# ============================================
# Application Settings
# ============================================

PORT=8080
CACHE_DIR=./cache
DATA_DIR=./data
GENERATED_DIR=./generated

# ============================================
# Model Configuration
# ============================================
# Provider: openai, anthropic, deepseek, or any OpenAI-compatible provider
# For ModelScope, use "openai" as provider with custom baseURL

TARS_MODEL_PROVIDER=openai

# Model ID: the specific model to use
TARS_MODEL_NAME=Qwen/Qwen3-Coder-480B-A35B-Instruct

# Base URL: for OpenAI-compatible APIs (leave empty for official OpenAI)
TARS_MODEL_BASE_URL=https://api-inference.modelscope.cn/v1

# API Key: will use TARS_MODEL_API_KEY first, then fall back to provider-specific keys
# For ModelScope, use MODELSCOPE_API_KEY; for DeepSeek, use DEEPSEEK_API_KEY
TARS_MODEL_API_KEY=${MODELSCOPE_API_KEY}
