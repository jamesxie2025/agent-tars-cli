# Agent TARS CLI Configuration
# Copy this file to .env and fill in your API keys

# ============================================
# Model Provider API Keys
# ============================================

# ModelScope (Qwen) - For Chinese users
MODELSCOPE_API_KEY=

# DeepSeek
DEEPSEEK_API_KEY=

# OpenAI (GPT-4o, etc.)
OPENAI_API_KEY=

# Anthropic (Claude)
ANTHROPIC_API_KEY=

# VolcEngine (Doubao/豆包)
VOLCENGINE_API_KEY=

# ============================================
# Optional MCP Tools API Keys
# ============================================

# Brave Search (for web search)
BRAVE_API_KEY=

# GitHub (for repository operations)
GITHUB_TOKEN=

# PostgreSQL (connection string)
POSTGRES_CONNECTION_STRING=

# ============================================
# Application Settings
# ============================================

PORT=8080
CACHE_DIR=/app/cache
DATA_DIR=/app/data
GENERATED_DIR=/app/generated

# ============================================
# Model Configuration
# ============================================
# Configure which model to use by setting these variables

# Example 1: Using ModelScope (OpenAI-compatible API)
TARS_MODEL_PROVIDER=openai
TARS_MODEL_NAME=Qwen/Qwen3-Coder-480B-A35B-Instruct
TARS_MODEL_BASE_URL=https://api-inference.modelscope.cn/v1/
TARS_MODEL_API_KEY=

# Example 2: Using Official OpenAI
# TARS_MODEL_PROVIDER=openai
# TARS_MODEL_NAME=gpt-4o
# TARS_MODEL_BASE_URL=
# TARS_MODEL_API_KEY=

# Example 3: Using Anthropic Claude
# TARS_MODEL_PROVIDER=anthropic
# TARS_MODEL_NAME=claude-3-7-sonnet-latest
# TARS_MODEL_BASE_URL=
# TARS_MODEL_API_KEY=

# Example 4: Using DeepSeek
# TARS_MODEL_PROVIDER=deepseek
# TARS_MODEL_NAME=deepseek-chat
# TARS_MODEL_BASE_URL=
# TARS_MODEL_API_KEY=

# Example 5: Using VolcEngine (Doubao)
# TARS_MODEL_PROVIDER=volcengine
# TARS_MODEL_NAME=doubao-1-5-thinking-vision-pro-250428
# TARS_MODEL_BASE_URL=
# TARS_MODEL_API_KEY=
